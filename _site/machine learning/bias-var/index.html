<!DOCTYPE html>
<html>
<!--
====================================================
    __  ____  ______________  _______ ___    __ 
   / / / /  |/  / ____/   \ \/ / ___//   |  / / 
  / /_/ / /|_/ / /_  / /| |\  /\__ \/ /| | / /  
 / __  / /  / / __/ / ___ |/ /___/ / ___ |/ /___
/_/ /_/_/  /_/_/   /_/  |_/_//____/_/  |_/_____/
                                                     
====================================================
Author: Hossain Mohammad Faysal
Profile: https://www.facebook.com/hmfaysal
Version: 1.0
Description: Awesome dude, awesome life
====================================================
-->
<head>
    <script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script> 

<meta charset="utf-8">
<title>BIAS-VARIANCE &vert; TK_BLOG</title>
<meta name="description" content="Evolution">
<meta name="keywords" content="bias-variance tradeoff, blog">



<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Bias-Variance">
<meta property="og:description" content="Evolution">
<meta property="og:url" content="/machine%20learning/bias-var">
<meta property="og:site_name" content="TK_blog">
<meta property="og:image" content="/images/">





<link rel="canonical" href="/machine%20learning/bias-var">
<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="TK_blog Feed">
<link rel="author" href="https://plus.google.com/u/0/102602916593522619858?rel=author">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />


    <link href='http://fonts.googleapis.com/css?family=Montserrat:400,700|Open+Sans:400,600,300,800,700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" href="/assets/css/font-awesome.min.css">
    <link rel="stylesheet" href="/assets/css/vendor/normalize.css">
    <link rel="stylesheet" href="/assets/css/vendor/foundation.min.css">
    <link rel="stylesheet" href="/assets/css/style.css">
    <link rel="stylesheet" href="/assets/css/post.css">
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="/assets/js/vendor/jquery-1.11.1.min.js"><\/script>')</script>
    





<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/images/apple-touch-icon-144x144-precomposed.png">

</head>
<body class="post-template" itemscope itemtype="http://schema.org/WebPage">  

        <main id="summer-post-container-simple" class="summer-post-container-simple" role="main">
            <header class="summer-post-header-simple">
                <div class="summer-post-menu-header-simple">

                    <a class="summer-blog-logo" href="">
                        <img src="/images/logo.png" alt="Blog Logo" />
                    </a>

                <div class="summer-blog-menu">      
    <div class="summer-mobile-menu show-for-small">
        <a href="#"><i class="fa fa-bars"></i></a>
    </div>
    <ul class="summer-menu">
        <li class="summer-mobile-close-btn show-for-small text-right">
            <a href="#"><i class="fa fa-times"></i></a>
        </li>

            <li>
                    <a href="/">Home</a>
                 </li>

            <li>
                    <a href="/featured">Featured Posts</a>
                 </li>

            <li>
                    <a href="/categories">Categories</a>
                 </li>

            <li>
                    <a href="/about">About</a>
                 </li>
            
           <li><a href="/feed.xml" title="Atom/RSS feed"><i class="icon-rss"></i> Feed</a></li>
    </ul>

</div>
            </div>

                <div class="summer-post-title-simple row">
                    <div class="small-12 columns">
                        <div class="summer-post-meta-simple">
                            <h1>Bias-Variance</h1>
                            <p>by <strong>Ping Jin</strong> &#8212; on <a href="/tags/index.html#bias-variance tradeoff, blog" data-toggle="tooltip" title="Posts tagged with bias-variance tradeoff, blog" rel="tag">bias-variance tradeoff, blog</a> <strong><time datetime="2013-11-13T00:00:00+06:00">13 Nov 2013</time></strong></p>
                        </div>
                    </div>
                </div>
            </header>

        <article class="summer-post-content post tag-simple">
            <div><p>Bias-variance tradeoff is a very basic and important topic in machine learning. It basically tells us what makes up the generalization error of a hypothesis or even a leaner and the involved tradeoff between the bias and variance. By knowing this, we can better choose the learner and hypothesis that achieves low generalization errors.</p>

<h1 id="assumptions">1. Assumptions</h1>

<p>All examples are <script type="math/tex">i.i.d</script>, from the joint distribution <script type="math/tex">P(X, Y)</script>. In this article, uppercase letters represent the random variables, while lowercase letters represent constant values.</p>

<h1 id="three-levels">2. Three levels</h1>

<ul>
  <li><strong>Prediction</strong>: Given a dataset <script type="math/tex">d</script>, the hypothesis learned from this dataset, and the value of <script type="math/tex">x</script>. The prediction <script type="math/tex">h(x)</script> can be evaluated by the error . </li>
</ul>

<script type="math/tex; mode=display">
E_{Y}[err(h(x|d), Y)]
</script>

<ul>
  <li><strong>Hypothesis</strong>: A hypothesis maps <em>X</em> to <em>Y</em>. It can be evaluated by the quality of predictions. It means that we want to measure the expected error of the hypothesis learned from some training set <script type="math/tex">d</script> over the distribution <script type="math/tex">P(X, Y)</script>.</li>
</ul>

<script type="math/tex; mode=display">
E_{X,Y}[err(h(X|d), Y)]
</script>

<ul>
  <li><strong>Learner</strong>: A learner maps <em>dataset D</em> to <em>hypothesis h</em>. It can be evaluated by the quality of hypothesis. It means that we want to measure the expectation of the performance of the hypotheses over different training datasets <script type="math/tex">D</script>.</li>
</ul>

<script type="math/tex; mode=display">
E_{D}[E_{X,Y}[err(h(X|D), Y)]]
</script>

<h1 id="error-function">3. Error function</h1>

<p>So let us focus on the case with <script type="math/tex">L2</script> error function. </p>

<script type="math/tex; mode=display">\begin{equation}
	err(h(x|d), Y) = (h(x|d) - Y)^2
\end{equation}</script>

<h1 id="analysis-for-evaluation-of-predictions">4. Analysis for evaluation of predictions</h1>

<p>For a given <script type="math/tex">x</script> and <script type="math/tex">h(x)</script>, we measure our prediction over the distribution <script type="math/tex">P(Y\vert x)</script></p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
	\begin{split}
		 E_{Y|x}[err(h(x), Y)] &= E_{Y|x}[(h(x) - Y)^2]\\
		&= E_{Y|x}[(h(x) -E[Y|x]+E[Y|x] - Y)^2]\\
		&= E_{Y|x}[(h(x) -E[Y|x])^2] + E_{Y|x}[(E[Y|x] - Y)^2] \\
		&+ 2 E_{Y|x}[(h(x)-E[Y|x])(E[Y|x] - Y)]\\
		&= (h(x) -E[Y|x])^2 + E_{Y|x}[(E[Y|x] - Y)^2] \\		
	\end{split}
\end{equation} %]]></script>

<ul>
  <li><strong>Fisrt term</strong>: the square of the bias</li>
  <li><strong>Second term</strong>: the variance of the variable <script type="math/tex">Y\vert x</script>, which is a property of the distribution and thus totally out of our control.</li>
</ul>

<p>And from the above derivation, we know that the hypothesis that minimizes the expected error of our prediction is</p>

<script type="math/tex; mode=display">
h^{opt}(x) = E[Y|x].
</script>

<h1 id="analysis-for-evaluation-of-hypotheses">5. Analysis for evaluation of hypotheses</h1>

<p>Given the training set <script type="math/tex">d</script>, we measure the hypothesis learned from this set with the expected error of its predictions over the distribution of all possible sample pair <script type="math/tex">P(X, Y)</script>.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
	\begin{split}
		 E_{X, Y}[err(h(X|d), Y)] &= E_{X, Y}[(h(X|d) - Y)^2]\\
		&= E_{X}\{E_{Y|X}[(h(X|d) -E_{Y|X}[Y])^2] + E_{Y|X}[(E_{Y|X}[Y] - Y)^2]\}
	\end{split}
\end{equation} %]]></script>

<h1 id="analysis-for-evaluation-of-learner">6. Analysis for evaluation of learner</h1>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
	\begin{split}
		 E_{D}\{E_{X, Y}[err(h(X|D), Y)]\} &= E_{D}\{E_{X, Y}[(h(X|D) - Y)^2]\}\\
		 &= E_{D}\{E_{X,Y}[(h(X|D) -E_{Y|X}[Y])^2 + E_{X,Y}[(E_{Y|X}[Y] - Y)^2]\}\\
		&= E_{X,Y} \{ E_{D}[(h(X|D) -E_{D}[h(X|D)])^2 + E_{D}[(E_{D}[h(X|D)] - E_{Y|X}[Y])^2]] \\
		& + 2 E_{D}[(h(X|D) -E_{D}[h(X|D)])(E_{D}[h(X|D)] - E_{Y|X}[Y]) \} \\
		&+ E_{X,Y}[(E_{Y|X}[Y] - Y)^2]\\
		&= E_{X,Y} \{ E_{D}[(h(X|D) -E_{D}[h(X|D)])^2]\} \\&
		+ E_{X,Y} \{(E_{D}[h(X|D)] - E_{Y|X}[Y])^2 \}+ E_{X,Y}[(E_{Y|X}[Y] - Y)^2]\\		
	\end{split}
\end{equation} %]]></script>

<ul>
  <li>The first two terms make the <strong>approximation error</strong> together. 
    <ul>
      <li><strong>First term</strong>: the variance of our prediction over different training sets <script type="math/tex">D</script>. </li>
      <li><strong>Second term</strong>: the bias, i.e., how well our prediction approximates the true <script type="math/tex">Y</script>. </li>
    </ul>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Third term: the expected variance of $$Y</td>
          <td>X<script type="math/tex"> over the distribution of </script>P(X)$$, i.e. the random noise.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h1 id="furthe-analysis">7. Furthe analysis</h1>

<p>Let </p>

<script type="math/tex; mode=display">
\hat{E}_{X, Y}[err(f(X), Y)] = \frac{1}{t} \sum^{t}_{i = 1} err(f(x_i), y_i),
</script>

<p>where <script type="math/tex">(x_i,y_i) \in D</script>, be the error of a certain hypothesis on training set.</p>

<p>Now suppose we have a hypothesis space <script type="math/tex">H</script>, <script type="math/tex">\hat{h}(X\vert D)</script> is the hypothesis <script type="math/tex">\in H</script> that minimizes the <script type="math/tex">MSE</script> on training dataset <script type="math/tex">D</script>, i.e.,</p>

<script type="math/tex; mode=display">
\hat{h}(X|D) = argmin_{h \in H} \hat{E}_{X,Y}[(h(X) - Y)^2]
</script>

<p>and <script type="math/tex">h^*(X)</script> is the hypothesis <script type="math/tex">\in H</script> that minimizes the expected <script type="math/tex">MSE</script> over <script type="math/tex">P(X, Y)</script>,i.e. </p>

<script type="math/tex; mode=display">
h^*(X) = argmin_{h \in H} E_{X,Y}[(h(X) - Y)^2]
</script>

<p>It is easy to see that </p>

<script type="math/tex; mode=display">
E_{D}[\hat{h}(X|D)] = h^*(X)
</script>

<p>Then we consider about the expected error of this learner</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
	\begin{split}
		 E_{D}\{E_{X, Y}[err(\hat{h}(X|D), Y)]\} &= E_{D}\{E_{X, Y}[(\hat{h}(X|d) - Y)^2]\}\\
		&= E_{X,Y} \{ E_{D}[(\hat{h}(X|D) - h^*(X))^2 + E_{D}[(h^*(X) - Y)^2]]\\
		& + 2 E_{D}[(\hat{h}(X|D) -h^*(X))](h(X) - Y) \}\\
		&= E_{X} \{ E_{D}[(\hat{h}(X|D) - h^*(X))^2]\} + E_{X,Y}\{(h^*(X) - Y)^2\}\\
	\end{split}
\end{equation} %]]></script>

<ul>
  <li><strong>First term</strong>: the variance of our learner, as <script type="math/tex">E_{D}[\hat{h}(X \vert D)] = h^*(X)</script>. </li>
  <li><strong>Second term</strong>: the combination of the bias and noise and also reppresent the lowest possible MSE on future sample, as <script type="math/tex">h^*(X) = argmin_{h \in H} E_{X,Y}[(h(X) - Y)^2]</script>.</li>
</ul>

<p>As <script type="math/tex">h_*(X)</script> is <strong>does not depend on training dataset D</strong>, we have </p>

<script type="math/tex; mode=display">
E_{X, Y}[(h^*(X) - Y)^2] = E_{D}\hat{E}_{X, Y}[(h^*(X) - Y)^2]
</script>

<p>which means that the training error of <script type="math/tex">h^*</script> is an <strong>unbiased estimate</strong> of its test error.</p>

<p>Then for <script type="math/tex">\hat{E}_{X, Y}[(h^*(X) - Y)^2]</script>, we have </p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
	\begin{split}
\hat{E}_{X, Y}[(h^*(X) - Y)^2] 
		&= \hat{E}_{X, Y}[(h^*(X) - \hat{h}(X|D) + \hat{h}(X|D) - Y)^2]\\
		&= \hat{E}_{X, Y}[(h^*(X) - \hat{h}(X|D))^2] + \hat{E}_{X, Y}[(\hat{h}(X|D) - Y)^2]\\
		& + 2 \hat{E}_{X, Y}[(h^*(X) - \hat{h}(X|D))(\hat{h}(X|D) - Y)]\\
		&= \hat{E}_{X, Y}[(h^*(X) - \hat{h}(X|D))^2] + \hat{E}_{X, Y}[(\hat{h}(X|D) - Y)^2]
	\end{split}
\end{equation} %]]></script>

<p>So we have </p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{equation}
	\begin{split}
		 E_{D}\{E_{X, Y}[err(\hat{h}(X|D), Y)]\} 
		 &=  E_{D}E_{X,Y}[(\hat{h}(X|D) - h^*(X))^2] + E_{X, Y}[(h^*(X) - Y)^2]\\
		 &= E_{D}E_{X,Y}[(\hat{h}(X|D) - h^*(X))^2] + E_{D}\hat{E}_{X, Y}[(h^*(X) - Y)^2]\\
		 &= E_{D} E_{X}[(\hat{h}(X|D) - h^*(X))^2] + E_{D}[\hat{E}_{X}[(\hat{h}(X|D)-h^*(X))^2]]\\ 
		 &+ E_{D}[\hat{E}_{X, Y}[(\hat{h}(X|D) - Y)^2]]\\
	\end{split}
\end{equation} %]]></script>

<ul>
  <li><strong>First term</strong>: variance of the leaner for future sample, as said above; </li>
  <li><strong>Second term</strong>: the variance of the learner on training dataset;</li>
  <li><strong>Third term</strong>: the leaner’s <script type="math/tex">MSE</script> on training set, i.e. the expected training error. So we can easily conclude that for a learner, <strong>the expected test error <script type="math/tex">\geq</script> optimal test error <script type="math/tex">\geq</script> expected training error</strong>.</li>
</ul>

<h1 id="the-tradeoff">8. The Tradeoff</h1>

<h2 id="increase-the-size-of-training-set-t--vert-d-vert">Increase the size of training set <script type="math/tex">t = \vert D \vert</script></h2>

<ul>
  <li>the optimal test error <script type="math/tex">E_{X, Y}[(h^*(X) - Y)^2]</script> does not change
    <ul>
      <li>the expected training error increases</li>
      <li>the training variance decreases</li>
    </ul>
  </li>
  <li>the variance on future samples decreases</li>
</ul>

<p>Thus the overall expected test error decreases. There is no tradeoff in this part.</p>

<h2 id="increase-the-repressiveness-of-the-hypothesis-space">Increase the repressiveness of the hypothesis space</h2>

<ul>
  <li>the optimal test error <script type="math/tex">E_{X, Y}[(h^*(X) - Y)^2]</script> decreases
    <ul>
      <li>the expected training error decreases</li>
      <li>the training variance increases</li>
    </ul>
  </li>
  <li>the variance on future samples increases</li>
</ul>

<p>We don’t know if the whole thing decreases or increases. It is a trade-off.</p>

<h1 id="reference">9. Reference</h1>
<p>[1] Prof. Schuurmans’s notes on Bias-Variance </p>

            </div>
        </article>
        <div class="cf"></div>
        <div class="row text-center">
            <section class="summer-post-share">
                <a class="twitter-icon" href="https://twitter.com/intent/tweet?text=&quot;Bias-Variance&quot;%20/machine%20learning/bias-var%20via%20&#64;"
                    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
                    <i class="fa fa-twitter"></i>
                </a>
                <a class="facebook-icon" href="https://www.facebook.com/sharer/sharer.php?u=/machine%20learning/bias-var"
                    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
                    <i class="fa fa-facebook"></i>
                </a>
                <a class="google-icon" href="https://plus.google.com/share?url=/machine%20learning/bias-var"
                   onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;" title="Share on Google+">
                    <i class="fa fa-google-plus"></i>
                </a>
            </section>
        </div>
        <div class="cf"></div>
        
            <div class="summer-author-info">
                <div class="row">
                    <section class="summer-post-author small-12 columns">
                        
                            <img src="/images/bio.png" class="summer-post-author-avatar" alt="Ping Jin's photo">
                        
                        
                            <span class="author-label">Author</span>
                            <h1>Ping Jin</h1>
                        
                        
                            <p><a href="mailto:pjin1@ualberta.ca" class="author-website">pjin1@ualberta.ca</a></p>
                        
                        
                            <p>Awesome Dude, Awesome Life</p>
                        
                    </section>
                </div>
            </div> 
        
        <div class="cf"></div>
        
        <section class="summer-disqus row">
    <div class="small-12 columns">
        <h1 class="summer-comments-header">Comments</h1>
        <div id="disqus_thread"></div>
        <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'tkcrown'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    </div>
</section>

        <div class="cf"></div>

    <footer class="summer-site-footer">
    <div class="copyright">
         <section>All content copyright <a href="/about">Ping Jin</a> &copy; 2014 &bull; All rights reserved.</section>
         <section>Proudly published with <a class="icon-ghost" href="https://jekyllrb.com/">Jekyll</a></section>
    </div>
    <div class="social-icons">
        
        
        
        <a href="https://plus.google.com/u/0/102602916593522619858">
            <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x fa-inverse"></i>
                <i class="fa fa-google-plus fa-stack-1x"></i>
            </span>
        </a>
        
        
        
        <a href="http://github.com/https://github.com/tkcrown">
            <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x fa-inverse"></i>
                <i class="fa fa-github fa-stack-1x"></i>
            </span>
        </a>
        
        
    </div>
    
    <div class="cf"></div>
</footer> 
</main>    
    <script src="/assets/js/vendor/modernizr.js"></script>
    <script src="/assets/js/foundation.min.js"></script>
    <script src="/assets/js/vendor/background-check.js"></script>
    <script src="/assets/js/vendor/post-header-animations.js"></script>
    <script src="/assets/js/summer.js"></script>

    <script>
      $(document).foundation();
    </script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45812015-1', 'auto');
  ga('require', 'displayfeatures');
  ga('send', 'pageview');

</script>
 
</body>
</html>
